# Phase IV Implementation Plan: Local Kubernetes with AI-Generated Infrastructure

**Feature**: Local Kubernetes Deployment with Minikube
**Branch**: `004-phase4-kubernetes`
**Created**: 2026-01-07
**Status**: Planning
**Execution Mode**: AI-First Infrastructure (Zero Manual Code)

---

## Executive Summary

This plan outlines the step-by-step execution strategy for deploying the Phase III Todo application to a local Kubernetes cluster using Minikube, where **all infrastructure code is generated by AI agents**. The plan follows the SpecKit Plus methodology and ensures zero manual infrastructure code.

**Key Principle**: Every Dockerfile, Kubernetes manifest, and Helm chart will be AI-generated, validated, and version-controlled.

---

## Table of Contents

1. [Planning Overview](#planning-overview)
2. [Architecture Decisions](#architecture-decisions)
3. [Execution Phases](#execution-phases)
4. [Detailed Implementation Steps](#detailed-implementation-steps)
5. [Validation Strategy](#validation-strategy)
6. [Risk Mitigation](#risk-mitigation)
7. [Success Criteria](#success-criteria)
8. [Rollback Plan](#rollback-plan)

---

## Planning Overview

### Objectives

1. **Primary Goal**: Deploy Todo app to local Kubernetes (Minikube) with 100% AI-generated infrastructure
2. **Secondary Goal**: Demonstrate AI-first DevOps workflows using SpecKit Plus
3. **Tertiary Goal**: Establish reusable patterns for AI-generated infrastructure

### Constraints

- ‚úÖ **MUST**: All infrastructure code AI-generated (Dockerfiles, K8s manifests, Helm charts)
- ‚úÖ **MUST**: Follow SpecKit Plus workflow (`/sp.plan`, `/sp.tasks`, `/sp.implement`)
- ‚úÖ **MUST**: All infrastructure validated before deployment
- ‚úÖ **MUST**: Document all AI prompts in PHRs (Prompt History Records)
- ‚ùå **MUST NOT**: Manually write any Dockerfile, YAML, or Helm template
- ‚ùå **MUST NOT**: Copy-paste infrastructure code from templates or examples

### Dependencies

**Prerequisites**:
- Phase I (CLI) completed and functional
- Phase II (Web) completed and functional
- Phase III (AI Chat) completed and functional
- Local development environment with:
  - Docker Desktop installed
  - 8GB+ RAM available for Minikube
  - kubectl CLI installed
  - Helm 3 installed

**External Services** (unchanged from Phase III):
- Neon PostgreSQL (cloud-hosted database)
- OpenAI API (GPT-4o for chat functionality)

---

## Architecture Decisions

### ADR-001: Minikube as Local Kubernetes Platform

**Decision**: Use Minikube for local Kubernetes development

**Rationale**:
- Industry-standard local K8s solution
- Excellent addon ecosystem (Ingress, metrics-server)
- Cross-platform compatibility (macOS, Linux, Windows)
- Lightweight and resource-efficient
- Strong community support

**Alternatives Considered**:
- Docker Desktop Kubernetes (limited addon support)
- kind (Kubernetes in Docker - more complex setup)
- k3s (lightweight but less common for local dev)

**Consequences**:
- Single-node cluster only (no multi-node HA testing)
- Requires separate installation from Docker Desktop
- Ingress requires addon enablement

---

### ADR-002: Helm 3 for Application Packaging

**Decision**: Use Helm 3 as the Kubernetes package manager

**Rationale**:
- De facto standard for K8s application packaging
- Parameterized deployments via values.yaml
- Easy rollback and upgrade mechanisms
- Templating reduces YAML duplication
- AI agents can generate Helm charts from manifests

**Alternatives Considered**:
- Kustomize (built into kubectl, but less flexible)
- Raw Kubernetes manifests (no parameterization)
- Skaffold (focused on dev workflow, not packaging)

**Consequences**:
- Additional learning curve for Helm syntax
- AI agents must understand Helm templating
- Two-step deployment (manifests ‚Üí Helm chart)

---

### ADR-003: AI-Generated Infrastructure Code (üåü Core Innovation)

**Decision**: All infrastructure code must be AI-generated, no manual creation allowed

**Rationale**:
- Demonstrates AI-first DevOps capabilities
- Aligns with SpecKit Plus AI agent methodology
- Faster iteration (no manual YAML editing)
- Consistency across all infrastructure
- Educational value for AI-assisted infrastructure

**Alternatives Considered**:
- Manual Dockerfiles with AI review (rejected: not AI-first)
- AI-assisted but human-written (rejected: not 100% AI)
- Templates with AI customization (rejected: violates zero-manual constraint)

**Consequences**:
- Must validate all AI outputs thoroughly
- Requires precise, well-crafted prompts
- AI must understand K8s best practices
- May require iterative prompt refinement

---

### ADR-004: Stateless Application Design

**Decision**: Maintain stateless architecture for frontend and backend

**Rationale**:
- Aligns with existing Phase III architecture
- Enables horizontal scaling in Kubernetes
- Simplifies pod replacement and rolling updates
- No persistent volumes needed (database is external)

**Consequences**:
- All state stored in external Neon PostgreSQL
- Session management via JWT (no server-side sessions)
- No file uploads or local storage

---

### ADR-005: NGINX Ingress Controller

**Decision**: Use NGINX Ingress Controller for HTTP routing

**Rationale**:
- Most widely used Ingress controller
- Built-in Minikube addon (easy enablement)
- Supports path-based and host-based routing
- Good performance for local development

**Alternatives Considered**:
- Traefik (more complex configuration)
- HAProxy (overkill for local dev)
- NodePort services (no hostname routing)

**Consequences**:
- Requires /etc/hosts configuration for local DNS
- Addon must be enabled in Minikube
- Limited to HTTP/HTTPS (no TCP/UDP)

---

## Execution Phases

### Phase 1: Environment Setup & Validation (Week 1, Day 1-2)
**Duration**: 4-6 hours
**Objective**: Prepare local environment for Kubernetes deployment

**Activities**:
1. Install and configure Minikube
2. Install kubectl CLI
3. Install Helm 3
4. Verify environment readiness
5. Create project directory structure

**Deliverables**:
- Minikube cluster running (4 CPU, 8GB RAM)
- kubectl configured and connected
- Helm 3 installed and functional
- Ingress addon enabled
- Environment validation script

**Acceptance Criteria**:
- `minikube status` shows "Running"
- `kubectl cluster-info` returns cluster details
- `helm version` shows v3.x.x
- `kubectl get pods -n ingress-nginx` shows Ingress controller running

---

### Phase 2: AI-Generate Dockerfiles (Week 1, Day 2-3)
**Duration**: 4-6 hours
**Objective**: Generate production-ready Dockerfiles for frontend and backend

**Activities**:
1. Create AI prompts for frontend Dockerfile (Next.js)
2. Generate frontend Dockerfile via AI agent
3. Validate frontend Dockerfile syntax and best practices
4. Create AI prompts for backend Dockerfile (FastAPI)
5. Generate backend Dockerfile via AI agent
6. Validate backend Dockerfile syntax and best practices
7. Document all prompts in PHRs

**Deliverables**:
- `/frontend/Dockerfile` (AI-generated, multi-stage)
- `/backend/Dockerfile` (AI-generated, multi-stage)
- PHRs documenting AI generation process
- Dockerfile validation reports

**Acceptance Criteria**:
- Dockerfiles build successfully without errors
- Images use multi-stage builds (optimized size)
- Containers run as non-root users
- Health check endpoints defined
- No critical security vulnerabilities (Trivy scan)

**AI Prompts** (to be recorded in PHRs):
- Frontend: "Generate production-ready multi-stage Dockerfile for Next.js 16 with node:20-alpine, non-root user, health checks"
- Backend: "Generate production-ready multi-stage Dockerfile for FastAPI with python:3.12-slim, health check on /health, uvicorn ASGI server"

---

### Phase 3: Build & Test Docker Images (Week 1, Day 3-4)
**Duration**: 2-4 hours
**Objective**: Build Docker images and verify functionality

**Activities**:
1. Build frontend Docker image
2. Build backend Docker image
3. Test frontend container locally
4. Test backend container locally
5. Load images into Minikube registry
6. Verify image availability in Minikube

**Deliverables**:
- `todo-frontend:latest` image built and tested
- `todo-backend:latest` image built and tested
- Images loaded into Minikube
- Container test reports

**Acceptance Criteria**:
- `docker build` completes without errors
- Frontend container serves pages on port 3000
- Backend container responds to health checks on port 8000
- `minikube image ls | grep todo` shows both images
- Image sizes optimized (<500MB frontend, <300MB backend)

---

### Phase 4: AI-Generate Kubernetes Manifests (Week 1, Day 4-5)
**Duration**: 6-8 hours
**Objective**: Generate all Kubernetes resource manifests via AI

**Activities**:
1. Generate namespace.yaml
2. Generate ConfigMap (app-config)
3. Generate Secret (app-secrets with base64 encoding)
4. Generate frontend Deployment manifest
5. Generate backend Deployment manifest
6. Generate frontend Service manifest
7. Generate backend Service manifest
8. Generate Ingress manifest
9. Validate all manifests with `kubectl apply --dry-run`
10. Document all AI prompts in PHRs

**Deliverables**:
- `/k8s/namespace.yaml`
- `/k8s/configmap.yaml`
- `/k8s/secret.yaml`
- `/k8s/deployment-frontend.yaml`
- `/k8s/deployment-backend.yaml`
- `/k8s/service-frontend.yaml`
- `/k8s/service-backend.yaml`
- `/k8s/ingress.yaml`
- Manifest validation reports
- PHRs for all AI generations

**Acceptance Criteria**:
- All manifests validate with `kubectl apply --dry-run=client`
- Deployments specify resource requests/limits
- Health probes configured (liveness, readiness)
- ImagePullPolicy set to "Never" (local images)
- Ingress rules for todo.local and api.todo.local
- No validation errors or warnings

**Resource Specifications**:
- **Frontend**: 2 replicas, 100m-500m CPU, 128Mi-512Mi memory
- **Backend**: 2 replicas, 200m-1000m CPU, 256Mi-1Gi memory

---

### Phase 5: Deploy to Minikube (Raw Manifests) (Week 1, Day 5)
**Duration**: 2-3 hours
**Objective**: Deploy application using raw K8s manifests (pre-Helm)

**Activities**:
1. Create todo-app namespace
2. Apply ConfigMap and Secret
3. Apply frontend Deployment and Service
4. Apply backend Deployment and Service
5. Apply Ingress
6. Verify all resources created
7. Check pod status and logs
8. Test service connectivity

**Deliverables**:
- All resources deployed to todo-app namespace
- Pods running and ready
- Services accessible internally
- Ingress configured

**Acceptance Criteria**:
- `kubectl get pods -n todo-app` shows all pods "Running" (4 total: 2 frontend, 2 backend)
- `kubectl get svc -n todo-app` shows 2 ClusterIP services
- `kubectl get ingress -n todo-app` shows Ingress with hosts
- All health probes passing (green)
- No CrashLoopBackOff or ImagePullBackOff errors

---

### Phase 6: Configure Ingress & Local DNS (Week 1, Day 5)
**Duration**: 1-2 hours
**Objective**: Enable external access via Ingress

**Activities**:
1. Get Minikube IP address
2. Update /etc/hosts with local DNS entries
3. Verify Ingress controller routing
4. Test HTTP requests to todo.local
5. Test HTTP requests to api.todo.local

**Deliverables**:
- /etc/hosts updated with Minikube IP
- Ingress routing functional
- HTTP access verified

**Acceptance Criteria**:
- `curl http://todo.local` returns 200 OK
- `curl http://api.todo.local/health` returns JSON health status
- Browser access to http://todo.local shows frontend
- Frontend can reach backend via api.todo.local

---

### Phase 7: AI-Generate Helm Chart (Week 2, Day 1-2)
**Duration**: 6-8 hours
**Objective**: Convert K8s manifests to parameterized Helm chart

**Activities**:
1. Create AI prompt for Helm chart conversion
2. Generate Chart.yaml metadata
3. Generate values.yaml with defaults
4. Generate Helm templates from manifests
5. Generate _helpers.tpl for common labels
6. Generate NOTES.txt with post-install instructions
7. Validate Helm chart with `helm lint`
8. Template rendering test with `helm template`
9. Document AI prompts in PHRs

**Deliverables**:
- `/helm/todo-app/Chart.yaml`
- `/helm/todo-app/values.yaml`
- `/helm/todo-app/templates/*.yaml` (8 templates)
- `/helm/todo-app/templates/_helpers.tpl`
- `/helm/todo-app/templates/NOTES.txt`
- Helm lint report
- PHRs for chart generation

**Acceptance Criteria**:
- `helm lint ./helm/todo-app` returns 0 errors
- `helm template ./helm/todo-app` renders valid YAML
- values.yaml contains all parameterized values
- Chart follows Helm best practices
- NOTES.txt provides clear post-install instructions

**Parameterized Values** (in values.yaml):
- Replica counts (frontend, backend)
- Image names and tags
- Resource requests/limits
- Ingress hostnames
- ConfigMap data
- Secret data (base64 encoded)

---

### Phase 8: Deploy with Helm (Week 2, Day 2)
**Duration**: 2-3 hours
**Objective**: Deploy application using Helm chart

**Activities**:
1. Uninstall raw manifest deployment
2. Clean up todo-app namespace
3. Install Helm chart with default values
4. Verify deployment via Helm
5. Check pod status and logs
6. Test application functionality

**Deliverables**:
- Helm release "todo-app" deployed
- All resources managed by Helm
- Deployment verified

**Acceptance Criteria**:
- `helm list -n todo-app` shows "deployed" status
- `kubectl get pods -n todo-app` shows all pods running
- Helm release notes displayed correctly
- Application accessible via Ingress
- All Phase III features functional (auth, tasks, AI chat)

---

### Phase 9: Validation & Testing (Week 2, Day 3)
**Duration**: 4-6 hours
**Objective**: Comprehensive testing of deployed application

**Activities**:
1. Test pod health checks
2. Test service connectivity (ClusterIP)
3. Test Ingress routing
4. Test application features (auth, tasks, AI chat)
5. Test scaling (scale up/down)
6. Test rolling updates
7. Test configuration changes
8. Load testing (optional)
9. Document test results

**Deliverables**:
- Test plan document
- Test execution report
- Performance metrics
- Validation checklist (all items passed)

**Test Cases**:
1. **Pod Health**: All liveness/readiness probes passing
2. **Service Discovery**: Frontend can resolve backend service DNS
3. **Ingress Routing**: HTTP requests route to correct services
4. **User Authentication**: Register, login, logout workflows
5. **Task Management**: Create, read, update, delete tasks
6. **AI Chat**: Send messages, receive AI responses
7. **Scaling**: `kubectl scale deployment/todo-backend --replicas=3`
8. **Rolling Update**: Change image tag, apply, verify zero downtime
9. **Config Update**: Edit ConfigMap, restart pods, verify changes

**Acceptance Criteria**:
- All test cases pass without errors
- Frontend response time <500ms (p95)
- Backend response time <1s (p95)
- AI chat functionality works end-to-end
- Scaling responds within 2 minutes
- Rolling updates complete without pod failures

---

### Phase 10: Documentation & Handoff (Week 2, Day 4-5)
**Duration**: 4-6 hours
**Objective**: Document architecture, operations, and lessons learned

**Activities**:
1. Create architecture diagram (deployed state)
2. Document AI prompts used for infrastructure generation
3. Create runbooks for common operations
4. Document troubleshooting procedures
5. Record ADRs for all architectural decisions
6. Create final PHR for Phase IV completion
7. Update README with Phase IV instructions

**Deliverables**:
- Architecture diagram (as-built)
- AI prompts catalog (all PHRs)
- Operations runbook
- Troubleshooting guide
- ADRs (5 total)
- Updated README.md
- Phase IV completion PHR

**Documentation Structure**:
```
specs/004-phase4-kubernetes/
‚îú‚îÄ‚îÄ plan.md                    # This file
‚îú‚îÄ‚îÄ spec.md                    # Phase IV specification
‚îú‚îÄ‚îÄ tasks.md                   # Generated by /sp.tasks
‚îú‚îÄ‚îÄ architecture.md            # As-built architecture
‚îú‚îÄ‚îÄ runbook.md                 # Operations guide
‚îú‚îÄ‚îÄ troubleshooting.md         # Common issues and fixes
‚îî‚îÄ‚îÄ adr/
    ‚îú‚îÄ‚îÄ 001-minikube-platform.md
    ‚îú‚îÄ‚îÄ 002-helm-packaging.md
    ‚îú‚îÄ‚îÄ 003-ai-generated-infra.md
    ‚îú‚îÄ‚îÄ 004-stateless-design.md
    ‚îî‚îÄ‚îÄ 005-nginx-ingress.md
```

---

## Detailed Implementation Steps

### Step 1: Environment Setup

**Objective**: Install and configure local Kubernetes environment

**Prerequisites**: Docker Desktop installed

**Commands**:
```bash
# Install Minikube (macOS)
brew install minikube

# Install kubectl
brew install kubectl

# Install Helm 3
brew install helm

# Start Minikube with resources
minikube start --cpus=4 --memory=8192 --driver=docker

# Enable addons
minikube addons enable ingress
minikube addons enable metrics-server

# Verify installation
kubectl cluster-info
kubectl get nodes
helm version
```

**Validation**:
```bash
# Check Minikube status
minikube status
# Expected: host, kubelet, apiserver all "Running"

# Check Ingress controller
kubectl get pods -n ingress-nginx
# Expected: ingress-nginx-controller pod "Running"

# Check kubectl context
kubectl config current-context
# Expected: "minikube"
```

**Outputs**:
- Minikube cluster running
- kubectl configured to use minikube context
- Helm CLI installed
- Ingress addon enabled

---

### Step 2: Create Project Structure

**Objective**: Set up directory structure for Phase IV artifacts

**Commands**:
```bash
# Create directories
mkdir -p k8s
mkdir -p helm/todo-app/templates
mkdir -p specs/004-phase4-kubernetes/adr
mkdir -p .claude/agents
mkdir -p .claude/skills

# Create placeholder files
touch k8s/.gitkeep
touch helm/todo-app/.gitkeep
```

**Structure**:
```
to-do/
‚îú‚îÄ‚îÄ k8s/                       # Kubernetes manifests (AI-generated)
‚îú‚îÄ‚îÄ helm/todo-app/             # Helm chart (AI-generated)
‚îú‚îÄ‚îÄ specs/004-phase4-kubernetes/
‚îÇ   ‚îú‚îÄ‚îÄ spec.md
‚îÇ   ‚îú‚îÄ‚îÄ plan.md                # This file
‚îÇ   ‚îú‚îÄ‚îÄ tasks.md               # To be generated
‚îÇ   ‚îî‚îÄ‚îÄ adr/
‚îî‚îÄ‚îÄ .claude/
    ‚îú‚îÄ‚îÄ agents/
    ‚îÇ   ‚îî‚îÄ‚îÄ infrastructure-generator-agent.md
    ‚îî‚îÄ‚îÄ skills/
        ‚îú‚îÄ‚îÄ dockerfile-generation.md
        ‚îú‚îÄ‚îÄ kubernetes-manifest-generation.md
        ‚îî‚îÄ‚îÄ helm-chart-generation.md
```

---

### Step 3: AI-Generate Frontend Dockerfile

**Objective**: Generate production-ready Dockerfile for Next.js frontend

**AI Prompt**:
```
Analyze the Next.js 16 application in /mnt/g/d_data/speckit/hackathon2/part1/to-do/frontend
and generate a production-ready Dockerfile with these requirements:

1. Multi-stage build for optimization
2. Base image: node:20-alpine
3. Install dependencies in separate stage (npm ci)
4. Build Next.js app with standalone output mode
5. Final stage: minimal runtime image
6. Run as non-root user (uid 1001, username "nextjs")
7. Expose port 3000
8. Set environment variables:
   - NODE_ENV=production
   - NEXT_TELEMETRY_DISABLED=1
9. Use CMD ["node", "server.js"] for startup
10. Add labels for image metadata

Security requirements:
- No root user execution
- Minimal layers
- No unnecessary packages
- Use .dockerignore to exclude node_modules, .git, etc.

Output the complete Dockerfile ready to save to /frontend/Dockerfile
```

**Validation Steps**:
1. Save AI-generated Dockerfile to `/frontend/Dockerfile`
2. Create `.dockerignore` in `/frontend/`:
   ```
   node_modules
   .next
   .git
   .env*
   README.md
   ```
3. Build image: `docker build -t todo-frontend:latest ./frontend`
4. Verify build completes without errors
5. Test container: `docker run -p 3000:3000 todo-frontend:latest`
6. Scan for vulnerabilities: `trivy image todo-frontend:latest`

**Expected Output**:
- Dockerfile with 2-3 stages (deps, builder, runner)
- Image size <500MB
- No critical vulnerabilities
- Container starts successfully

**Record PHR**:
- Title: "AI-Generated Frontend Dockerfile for Next.js"
- Stage: "infrastructure"
- Prompt: <full prompt above>
- Response: <AI-generated Dockerfile>
- Outcome: "Dockerfile generated, validated, and committed"

---

### Step 4: AI-Generate Backend Dockerfile

**Objective**: Generate production-ready Dockerfile for FastAPI backend

**AI Prompt**:
```
Analyze the FastAPI application in /mnt/g/d_data/speckit/hackathon2/part1/to-do/backend
and generate a production-ready Dockerfile with these requirements:

1. Multi-stage build for optimization
2. Base image: python:3.12-slim
3. Install system dependencies in builder stage:
   - gcc
   - postgresql-client
4. Install Python dependencies from requirements.txt
5. Final stage: minimal runtime image
6. Run as non-root user (uid 1001, username "appuser")
7. Expose port 8000
8. Add health check: CMD curl -f http://localhost:8000/health || exit 1
9. Use CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
10. Set working directory /app
11. Copy only necessary files to final stage

Security requirements:
- No root user execution
- Minimal attack surface
- Health check for container monitoring
- Use .dockerignore to exclude .venv, __pycache__, .git, etc.

Output the complete Dockerfile ready to save to /backend/Dockerfile
```

**Validation Steps**:
1. Save AI-generated Dockerfile to `/backend/Dockerfile`
2. Create `.dockerignore` in `/backend/`:
   ```
   .venv
   __pycache__
   *.pyc
   .git
   .env*
   README.md
   tests/
   ```
3. Build image: `docker build -t todo-backend:latest ./backend`
4. Verify build completes without errors
5. Test container: `docker run -p 8000:8000 -e DATABASE_URL=... todo-backend:latest`
6. Test health endpoint: `curl http://localhost:8000/health`
7. Scan for vulnerabilities: `trivy image todo-backend:latest`

**Expected Output**:
- Dockerfile with 2 stages (builder, runner)
- Image size <300MB
- No critical vulnerabilities
- Health check returns 200 OK

**Record PHR**:
- Title: "AI-Generated Backend Dockerfile for FastAPI"
- Stage: "infrastructure"
- Prompt: <full prompt above>
- Response: <AI-generated Dockerfile>
- Outcome: "Dockerfile generated, validated, and committed"

---

### Step 5: Build and Load Docker Images

**Objective**: Build images locally and load into Minikube

**Commands**:
```bash
# Build frontend image
cd frontend
docker build -t todo-frontend:latest .
cd ..

# Build backend image
cd backend
docker build -t todo-backend:latest .
cd ..

# Verify images built
docker images | grep todo

# Load images into Minikube
minikube image load todo-frontend:latest
minikube image load todo-backend:latest

# Verify images in Minikube
minikube image ls | grep todo
```

**Validation**:
```bash
# Check image sizes
docker images --format "{{.Repository}}:{{.Tag}}\t{{.Size}}" | grep todo
# Expected: frontend <500MB, backend <300MB

# Test frontend locally
docker run -d -p 3000:3000 --name frontend-test todo-frontend:latest
curl http://localhost:3000
docker stop frontend-test && docker rm frontend-test

# Test backend locally (with env vars)
docker run -d -p 8000:8000 \
  -e DATABASE_URL="${DATABASE_URL}" \
  -e OPENAI_API_KEY="${OPENAI_API_KEY}" \
  -e JWT_SECRET="test-secret" \
  --name backend-test todo-backend:latest
curl http://localhost:8000/health
docker stop backend-test && docker rm backend-test
```

**Outputs**:
- `todo-frontend:latest` image built and loaded
- `todo-backend:latest` image built and loaded
- Images available in Minikube registry

---

### Step 6: AI-Generate Kubernetes Manifests

**Objective**: Generate all K8s resource manifests via AI

**6.1 Namespace**

**AI Prompt**:
```
Generate a Kubernetes Namespace manifest with:
- Name: todo-app
- Labels:
  - app: todo-app
  - environment: local
  - managed-by: helm

Output valid YAML for /k8s/namespace.yaml
```

**6.2 ConfigMap**

**AI Prompt**:
```
Generate a Kubernetes ConfigMap manifest with:
- Name: app-config
- Namespace: todo-app
- Data:
  - NEXT_PUBLIC_API_URL: "http://api.todo.local"
  - CORS_ORIGINS: "http://todo.local"
  - LOG_LEVEL: "INFO"
  - OPENAI_MODEL: "gpt-4o"
  - CONVERSATION_HISTORY_LIMIT: "10"

Output valid YAML for /k8s/configmap.yaml
```

**6.3 Secret**

**AI Prompt**:
```
Generate a Kubernetes Secret manifest with:
- Name: app-secrets
- Namespace: todo-app
- Type: Opaque
- Data (must be base64 encoded):
  - DATABASE_URL: <will be provided separately>
  - OPENAI_API_KEY: <will be provided separately>
  - JWT_SECRET: <will be provided separately>

Add a comment instructing user to replace placeholder values with:
echo -n "actual-value" | base64

Output valid YAML template for /k8s/secret.yaml
```

**6.4 Frontend Deployment**

**AI Prompt**:
```
Generate a Kubernetes Deployment manifest for Next.js frontend with:
- Name: todo-frontend
- Namespace: todo-app
- Replicas: 2
- Selector: app=todo-frontend
- Pod template:
  - Labels: app=todo-frontend, tier=frontend
  - Container:
    - Name: frontend
    - Image: todo-frontend:latest
    - ImagePullPolicy: Never
    - Ports: containerPort 3000, name "http"
    - Environment variables from ConfigMap "app-config":
      - NEXT_PUBLIC_API_URL
    - Environment variable: NODE_ENV=production
    - Resources:
      - Requests: cpu 100m, memory 128Mi
      - Limits: cpu 500m, memory 512Mi
    - Liveness probe: httpGet path "/" port 3000, initialDelaySeconds 30, periodSeconds 10
    - Readiness probe: httpGet path "/" port 3000, initialDelaySeconds 10, periodSeconds 5

Output valid YAML for /k8s/deployment-frontend.yaml
```

**6.5 Backend Deployment**

**AI Prompt**:
```
Generate a Kubernetes Deployment manifest for FastAPI backend with:
- Name: todo-backend
- Namespace: todo-app
- Replicas: 2
- Selector: app=todo-backend
- Pod template:
  - Labels: app=todo-backend, tier=backend
  - Container:
    - Name: backend
    - Image: todo-backend:latest
    - ImagePullPolicy: Never
    - Ports: containerPort 8000, name "http"
    - Environment variables from Secret "app-secrets":
      - DATABASE_URL (secretKeyRef)
      - OPENAI_API_KEY (secretKeyRef)
      - JWT_SECRET (secretKeyRef)
    - Environment variables from ConfigMap "app-config":
      - CORS_ORIGINS
      - LOG_LEVEL
      - OPENAI_MODEL
    - Resources:
      - Requests: cpu 200m, memory 256Mi
      - Limits: cpu 1000m, memory 1Gi
    - Liveness probe: httpGet path "/health" port 8000, initialDelaySeconds 30, periodSeconds 10
    - Readiness probe: httpGet path "/health" port 8000, initialDelaySeconds 10, periodSeconds 5

Output valid YAML for /k8s/deployment-backend.yaml
```

**6.6 Services**

**AI Prompt**:
```
Generate two Kubernetes Service manifests:

1. Frontend Service:
   - Name: todo-frontend
   - Namespace: todo-app
   - Type: ClusterIP
   - Selector: app=todo-frontend
   - Ports: port 80, targetPort 3000, protocol TCP, name "http"

2. Backend Service:
   - Name: todo-backend
   - Namespace: todo-app
   - Type: ClusterIP
   - Selector: app=todo-backend
   - Ports: port 80, targetPort 8000, protocol TCP, name "http"

Output two valid YAML documents separated by "---" for:
- /k8s/service-frontend.yaml
- /k8s/service-backend.yaml
```

**6.7 Ingress**

**AI Prompt**:
```
Generate a Kubernetes Ingress manifest with:
- Name: todo-ingress
- Namespace: todo-app
- Annotations:
  - nginx.ingress.kubernetes.io/ssl-redirect: "false"
- IngressClassName: nginx
- Rules:
  1. Host: todo.local
     - Path: / (pathType: Prefix)
     - Backend: service "todo-frontend", port 80
  2. Host: api.todo.local
     - Path: / (pathType: Prefix)
     - Backend: service "todo-backend", port 80

Output valid YAML for /k8s/ingress.yaml
```

**Validation for All Manifests**:
```bash
# Validate each manifest
kubectl apply --dry-run=client -f k8s/namespace.yaml
kubectl apply --dry-run=client -f k8s/configmap.yaml
kubectl apply --dry-run=client -f k8s/secret.yaml
kubectl apply --dry-run=client -f k8s/deployment-frontend.yaml
kubectl apply --dry-run=client -f k8s/deployment-backend.yaml
kubectl apply --dry-run=client -f k8s/service-frontend.yaml
kubectl apply --dry-run=client -f k8s/service-backend.yaml
kubectl apply --dry-run=client -f k8s/ingress.yaml

# Validate all at once
kubectl apply --dry-run=client -f k8s/
```

**Record PHRs**:
- Create PHR for each manifest generation
- Document all prompts and AI responses
- Record validation results

---

### Step 7: Deploy to Minikube (Raw Manifests)

**Objective**: Deploy application using raw K8s manifests

**Prerequisites**:
- Update `/k8s/secret.yaml` with actual base64-encoded secrets:
  ```bash
  echo -n "$DATABASE_URL" | base64
  echo -n "$OPENAI_API_KEY" | base64
  echo -n "$(openssl rand -hex 32)" | base64  # JWT_SECRET
  ```

**Commands**:
```bash
# Create namespace
kubectl apply -f k8s/namespace.yaml

# Apply ConfigMap and Secret
kubectl apply -f k8s/configmap.yaml
kubectl apply -f k8s/secret.yaml

# Apply Deployments
kubectl apply -f k8s/deployment-frontend.yaml
kubectl apply -f k8s/deployment-backend.yaml

# Apply Services
kubectl apply -f k8s/service-frontend.yaml
kubectl apply -f k8s/service-backend.yaml

# Apply Ingress
kubectl apply -f k8s/ingress.yaml

# Wait for rollout
kubectl rollout status deployment/todo-frontend -n todo-app
kubectl rollout status deployment/todo-backend -n todo-app
```

**Verification**:
```bash
# Check all resources
kubectl get all -n todo-app

# Check pods
kubectl get pods -n todo-app -o wide
# Expected: 4 pods (2 frontend, 2 backend) all "Running"

# Check services
kubectl get svc -n todo-app
# Expected: 2 ClusterIP services

# Check ingress
kubectl get ingress -n todo-app
# Expected: Ingress with 2 rules

# Check pod logs
kubectl logs -n todo-app -l app=todo-frontend --tail=20
kubectl logs -n todo-app -l app=todo-backend --tail=20

# Check events
kubectl get events -n todo-app --sort-by='.lastTimestamp'
```

**Troubleshooting**:
```bash
# If pods not starting
kubectl describe pod <pod-name> -n todo-app

# If ImagePullBackOff
kubectl get pod <pod-name> -n todo-app -o yaml | grep -A 5 image

# If CrashLoopBackOff
kubectl logs <pod-name> -n todo-app --previous
```

---

### Step 8: Configure Ingress & DNS

**Objective**: Enable external access via local DNS

**Commands**:
```bash
# Get Minikube IP
MINIKUBE_IP=$(minikube ip)
echo "Minikube IP: $MINIKUBE_IP"

# Add to /etc/hosts (requires sudo)
echo "$MINIKUBE_IP todo.local api.todo.local" | sudo tee -a /etc/hosts

# Verify Ingress address
kubectl get ingress -n todo-app
```

**Verification**:
```bash
# Test frontend
curl -I http://todo.local
# Expected: HTTP/1.1 200 OK

# Test backend
curl http://api.todo.local/health
# Expected: {"status": "healthy"}

# Test in browser
open http://todo.local
# Expected: Frontend loads successfully
```

---

### Step 9: AI-Generate Helm Chart

**Objective**: Convert manifests to Helm chart with parameterization

**AI Prompt for Chart.yaml**:
```
Generate a Helm Chart.yaml file with:
- apiVersion: v2
- name: todo-app
- description: "AI-powered Todo application with Next.js frontend and FastAPI backend"
- type: application
- version: 0.1.0
- appVersion: "1.0.0"
- keywords: ["todo", "ai", "chatbot", "kubernetes"]
- maintainers:
  - name: "AI Agent"
    email: "ai@example.com"

Output valid YAML for /helm/todo-app/Chart.yaml
```

**AI Prompt for values.yaml**:
```
Generate a Helm values.yaml file with parameterized values for:

frontend:
  replicaCount: 2
  image:
    repository: todo-frontend
    tag: latest
    pullPolicy: Never
  service:
    type: ClusterIP
    port: 80
    targetPort: 3000
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi
  env:
    apiUrl: "http://api.todo.local"

backend:
  replicaCount: 2
  image:
    repository: todo-backend
    tag: latest
    pullPolicy: Never
  service:
    type: ClusterIP
    port: 80
    targetPort: 8000
  resources:
    requests:
      cpu: 200m
      memory: 256Mi
    limits:
      cpu: 1000m
      memory: 1Gi
  env:
    corsOrigins: "http://todo.local"
    logLevel: "INFO"
    openaiModel: "gpt-4o"

ingress:
  enabled: true
  className: nginx
  hosts:
    - host: todo.local
      paths:
        - path: /
          pathType: Prefix
          service: frontend
    - host: api.todo.local
      paths:
        - path: /
          pathType: Prefix
          service: backend

secrets:
  databaseUrl: ""  # base64 encoded, provided via --set
  openaiApiKey: ""  # base64 encoded, provided via --set
  jwtSecret: ""  # base64 encoded, provided via --set

Output valid YAML for /helm/todo-app/values.yaml
```

**AI Prompt for Templates**:
```
Convert the following Kubernetes manifests to Helm templates with Go templating:

1. namespace.yaml ‚Üí templates/namespace.yaml
   - Use {{ .Release.Namespace }}

2. configmap.yaml ‚Üí templates/configmap.yaml
   - Parameterize data values from .Values.frontend.env and .Values.backend.env

3. secret.yaml ‚Üí templates/secret.yaml
   - Parameterize secret values from .Values.secrets.*

4. deployment-frontend.yaml ‚Üí templates/deployment-frontend.yaml
   - Parameterize:
     - replicas: {{ .Values.frontend.replicaCount }}
     - image: {{ .Values.frontend.image.repository }}:{{ .Values.frontend.image.tag }}
     - resources: {{ toYaml .Values.frontend.resources | nindent 12 }}

5. deployment-backend.yaml ‚Üí templates/deployment-backend.yaml
   - Parameterize:
     - replicas: {{ .Values.backend.replicaCount }}
     - image: {{ .Values.backend.image.repository }}:{{ .Values.backend.image.tag }}
     - resources: {{ toYaml .Values.backend.resources | nindent 12 }}

6. service-frontend.yaml ‚Üí templates/service-frontend.yaml
   - Parameterize port and targetPort from .Values.frontend.service

7. service-backend.yaml ‚Üí templates/service-backend.yaml
   - Parameterize port and targetPort from .Values.backend.service

8. ingress.yaml ‚Üí templates/ingress.yaml
   - Parameterize hosts from .Values.ingress.hosts
   - Add {{ if .Values.ingress.enabled }} conditional

Generate all 8 templates with proper Helm templating syntax.
```

**AI Prompt for _helpers.tpl**:
```
Generate a Helm _helpers.tpl file with these template definitions:

1. todo-app.name - Chart name
2. todo-app.fullname - Full name with release
3. todo-app.chart - Chart name and version
4. todo-app.labels - Common labels
5. todo-app.selectorLabels - Selector labels

Output valid template file for /helm/todo-app/templates/_helpers.tpl
```

**AI Prompt for NOTES.txt**:
```
Generate a Helm NOTES.txt template that displays after installation with:

1. Success message
2. Instructions to get Ingress IP
3. Instructions to update /etc/hosts
4. Frontend URL: http://todo.local
5. Backend health URL: http://api.todo.local/health
6. Instructions to view pods: kubectl get pods -n {{ .Release.Namespace }}
7. Instructions to view logs

Output valid template for /helm/todo-app/templates/NOTES.txt
```

**Validation**:
```bash
# Lint chart
helm lint ./helm/todo-app

# Template rendering (dry-run)
helm template todo-app ./helm/todo-app --debug

# Validate generated YAML
helm template todo-app ./helm/todo-app | kubectl apply --dry-run=client -f -
```

**Record PHRs**:
- Document all Helm generation prompts
- Record validation results
- Note any template syntax issues and fixes

---

### Step 10: Deploy with Helm

**Objective**: Deploy application using Helm chart

**Commands**:
```bash
# Uninstall raw manifest deployment (if exists)
kubectl delete -f k8s/ --ignore-not-found=true

# Install Helm chart
helm install todo-app ./helm/todo-app \
  -n todo-app \
  --create-namespace \
  --set secrets.databaseUrl="$(echo -n "$DATABASE_URL" | base64)" \
  --set secrets.openaiApiKey="$(echo -n "$OPENAI_API_KEY" | base64)" \
  --set secrets.jwtSecret="$(openssl rand -hex 32 | base64)"

# View release
helm list -n todo-app

# View post-install notes
helm get notes todo-app -n todo-app

# Check status
helm status todo-app -n todo-app
```

**Verification**:
```bash
# Check all resources
kubectl get all -n todo-app

# Check pods
kubectl get pods -n todo-app
# Expected: 4 pods running

# Test frontend
curl http://todo.local

# Test backend
curl http://api.todo.local/health

# View logs
kubectl logs -n todo-app -l app=todo-frontend --tail=20
kubectl logs -n todo-app -l app=todo-backend --tail=20
```

**Outputs**:
- Helm release "todo-app" deployed
- All resources managed by Helm
- Application accessible via Ingress

---

## Validation Strategy

### Validation Checklist

**Infrastructure Code Validation**:
- [ ] All Dockerfiles AI-generated (git history check)
- [ ] All K8s manifests AI-generated (git history check)
- [ ] All Helm templates AI-generated (git history check)
- [ ] Zero manual infrastructure code committed
- [ ] All AI prompts documented in PHRs

**Build Validation**:
- [ ] Frontend Docker image builds without errors
- [ ] Backend Docker image builds without errors
- [ ] Image sizes optimized (<500MB frontend, <300MB backend)
- [ ] No critical vulnerabilities (Trivy scan)
- [ ] Images loaded into Minikube

**Manifest Validation**:
- [ ] All manifests validate with `kubectl apply --dry-run`
- [ ] Helm chart lints with 0 errors
- [ ] Helm templates render valid YAML
- [ ] No YAML syntax errors

**Deployment Validation**:
- [ ] All pods in "Running" state
- [ ] All health probes passing (green)
- [ ] Services resolving correctly (ClusterIP)
- [ ] Ingress routing to correct services
- [ ] No CrashLoopBackOff errors
- [ ] No ImagePullBackOff errors

**Application Validation**:
- [ ] Frontend accessible at http://todo.local
- [ ] Backend health check returns 200 OK
- [ ] User registration works
- [ ] User login works
- [ ] Task creation works
- [ ] Task listing works
- [ ] Task update works
- [ ] Task deletion works
- [ ] AI chat functionality works

**Performance Validation**:
- [ ] Frontend response time <500ms (p95)
- [ ] Backend response time <1s (p95)
- [ ] Pod startup time <30s
- [ ] Scaling responds within 2 minutes

**Helm Validation**:
- [ ] Helm install succeeds
- [ ] Helm upgrade works
- [ ] Helm rollback works
- [ ] values.yaml parameterization works
- [ ] NOTES.txt displays correctly

---

## Risk Mitigation

### Risk 1: AI Generates Invalid Infrastructure Code

**Probability**: Medium
**Impact**: High
**Mitigation**:
- Validate all AI outputs with linters (helm lint, kubectl apply --dry-run)
- Use precise, detailed AI prompts with examples
- Iterate prompts if initial output is invalid
- Human review of all AI-generated code before commit
- Test locally before deployment

**Contingency**:
- If AI output is invalid after 3 iterations, escalate to human expert
- Document failed prompts in PHRs for learning

---

### Risk 2: Docker Images Too Large

**Probability**: Low
**Impact**: Medium
**Mitigation**:
- Use multi-stage builds (enforced in AI prompts)
- Use minimal base images (alpine, slim)
- Exclude unnecessary files with .dockerignore
- Validate image sizes before loading into Minikube

**Contingency**:
- If images >500MB (frontend) or >300MB (backend), refine Dockerfiles
- Use `docker history` to identify large layers
- Re-prompt AI with size constraints

---

### Risk 3: Pods Fail to Start (CrashLoopBackOff)

**Probability**: Medium
**Impact**: High
**Mitigation**:
- Test containers locally before Kubernetes deployment
- Verify environment variables and secrets are correct
- Use health check probes with reasonable delays
- Check pod logs immediately after deployment

**Contingency**:
- Use `kubectl describe pod` to identify failure reason
- Check logs with `kubectl logs <pod> --previous`
- Fix configuration and redeploy
- Document issue in troubleshooting guide

---

### Risk 4: Ingress Routing Fails

**Probability**: Low
**Impact**: Medium
**Mitigation**:
- Verify Ingress addon is enabled in Minikube
- Ensure /etc/hosts is updated correctly
- Test Ingress rules with curl before browser
- Check Ingress controller logs

**Contingency**:
- Restart Ingress controller: `kubectl delete pod -n ingress-nginx -l app.kubernetes.io/component=controller`
- Recreate Ingress resource
- Use NodePort services as temporary workaround

---

### Risk 5: Database Connection Fails from Pods

**Probability**: Low
**Impact**: High
**Mitigation**:
- Verify DATABASE_URL secret is correctly base64 encoded
- Test connection from local container before Kubernetes
- Ensure Neon database allows connections from any IP
- Check pod logs for connection errors

**Contingency**:
- Verify secret with: `kubectl get secret app-secrets -n todo-app -o jsonpath='{.data.DATABASE_URL}' | base64 -d`
- Test connection from debug pod
- Check Neon database firewall rules

---

## Success Criteria

### Phase IV Completion Criteria

**Infrastructure as Code**:
- ‚úÖ 100% of Dockerfiles AI-generated (verified by git history)
- ‚úÖ 100% of K8s manifests AI-generated (verified by git history)
- ‚úÖ 100% of Helm charts AI-generated (verified by git history)
- ‚úÖ Helm lint: 0 errors
- ‚úÖ kubectl validation: 0 errors
- ‚úÖ All AI prompts documented in PHRs

**Deployment**:
- ‚úÖ Minikube cluster running
- ‚úÖ All pods in "Running" state (4 total)
- ‚úÖ All health probes passing
- ‚úÖ Services resolving (2 ClusterIP)
- ‚úÖ Ingress configured and routing correctly
- ‚úÖ Helm release deployed successfully

**Functionality**:
- ‚úÖ Frontend accessible at http://todo.local
- ‚úÖ Backend health check returns 200 OK
- ‚úÖ User authentication works (register, login, logout)
- ‚úÖ Task CRUD operations work
- ‚úÖ AI chat functionality works end-to-end
- ‚úÖ Database persistence verified

**Performance**:
- ‚úÖ Frontend p95 response time <500ms
- ‚úÖ Backend p95 response time <1s
- ‚úÖ Pod startup time <30s
- ‚úÖ Scaling responds within 2 minutes

**Documentation**:
- ‚úÖ Architecture diagram created
- ‚úÖ Runbook documented
- ‚úÖ Troubleshooting guide created
- ‚úÖ 5 ADRs documented
- ‚úÖ All PHRs recorded
- ‚úÖ README updated with Phase IV instructions

---

## Rollback Plan

### Scenario 1: Helm Deployment Fails

**Steps**:
1. Check Helm release status: `helm status todo-app -n todo-app`
2. View error logs: `kubectl logs -n todo-app -l app=todo-backend --tail=100`
3. Uninstall release: `helm uninstall todo-app -n todo-app`
4. Fix issue in Helm chart
5. Re-install: `helm install todo-app ./helm/todo-app -n todo-app`

**Fallback**: Deploy with raw manifests (`kubectl apply -f k8s/`)

---

### Scenario 2: Application Not Functional After Deployment

**Steps**:
1. Rollback to previous Helm release: `helm rollback todo-app -n todo-app`
2. If no previous release, uninstall: `helm uninstall todo-app -n todo-app`
3. Revert to Phase III local development mode
4. Debug issue in development
5. Fix and redeploy

**Recovery Time Objective**: <30 minutes

---

### Scenario 3: Minikube Cluster Failure

**Steps**:
1. Stop Minikube: `minikube stop`
2. Delete cluster: `minikube delete`
3. Recreate cluster: `minikube start --cpus=4 --memory=8192`
4. Enable addons: `minikube addons enable ingress`
5. Redeploy application: `helm install todo-app ./helm/todo-app -n todo-app`

**Recovery Time Objective**: <1 hour

---

## Timeline & Milestones

### Week 1: Infrastructure Generation & Deployment

**Day 1-2** (8 hours):
- ‚úÖ Environment setup (Minikube, kubectl, Helm)
- ‚úÖ AI-generate Dockerfiles
- ‚úÖ Build and test Docker images

**Day 3-4** (10 hours):
- ‚úÖ AI-generate Kubernetes manifests (8 files)
- ‚úÖ Validate manifests
- ‚úÖ Deploy to Minikube with raw manifests
- ‚úÖ Configure Ingress and DNS

**Day 5** (6 hours):
- ‚úÖ Verify deployment
- ‚úÖ Test application functionality
- ‚úÖ Fix any deployment issues

### Week 2: Helm Chart & Validation

**Day 1-2** (10 hours):
- ‚úÖ AI-generate Helm chart
- ‚úÖ Validate Helm chart
- ‚úÖ Deploy with Helm
- ‚úÖ Verify Helm deployment

**Day 3** (6 hours):
- ‚úÖ Comprehensive testing
- ‚úÖ Performance validation
- ‚úÖ Scaling tests

**Day 4-5** (8 hours):
- ‚úÖ Documentation
- ‚úÖ ADRs
- ‚úÖ Runbooks
- ‚úÖ Phase IV completion PHR

**Total Estimated Time**: 48-60 hours (1.5-2 weeks)

---

## Next Steps

1. **Run `/sp.tasks`**: Generate atomic task breakdown from this plan
2. **Run `/sp.implement`**: Execute tasks with AI agents
3. **Document ADRs**: Create 5 ADRs for key decisions
4. **Record PHRs**: Document all AI prompts and responses
5. **Final Review**: Validate all acceptance criteria met
6. **Create PR**: Commit all changes and create pull request

---

## Appendix: AI Prompts Catalog

All AI prompts used in this plan are documented in PHRs under:
- `history/prompts/004-phase4-kubernetes/`

### Prompt Categories:
1. **Dockerfile Generation** (2 prompts)
   - Frontend Dockerfile
   - Backend Dockerfile

2. **Kubernetes Manifests** (8 prompts)
   - Namespace
   - ConfigMap
   - Secret
   - Frontend Deployment
   - Backend Deployment
   - Frontend Service
   - Backend Service
   - Ingress

3. **Helm Chart** (5 prompts)
   - Chart.yaml
   - values.yaml
   - Templates (8 files)
   - _helpers.tpl
   - NOTES.txt

**Total AI Prompts**: 15 major prompts

---

**Plan Version**: 1.0
**Last Updated**: 2026-01-07
**Status**: Ready for Task Generation (`/sp.tasks`)
**Next Command**: `/sp.tasks` to generate atomic implementation tasks
